{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj_c4RdlbySz"
   },
   "source": [
    "<h1>Atividade 02 - melhorar o desempenho de RP em conjunto de dados existentes</h1>\n",
    "<p>A atividade 02 visa trabalhar com um conjunto de dados pré-construído, onde as opções que o desenvolvedor tem, são de aplicar as técnicas de pré-processamento abaixo relacionadas:</p>\n",
    "<ul><li>Seleção</li>\n",
    "<li>Limpeza</li>\n",
    "<li>Codificação</li>\n",
    "<li>Enriquecimento</li>\n",
    "<li>Normalização</li>\n",
    "<li>Construção de Atributos</li>\n",
    "<li>Correção de Prevalência</li>\n",
    "<li>Partição do Conjunto de Dados</li>\n",
    "</ul>\n",
    "<p>Busque uma base de dados na UCI Machine Learning que seja indicada para problemas de classificação. (<a target=\"_blank\" href=\"https://archive.ics.uci.edu/datasets\">https://archive.ics.uci.edu/datasets</a>)</p>\n",
    "<p>Para esse exemplo, vou usar a base de câncer de mama (https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n83lcKbzgBnE"
   },
   "source": [
    "Opção 01 - carregue o arquivo de dados da pasta local para o colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrWY8dFDbuvO",
    "outputId": "93251ce6-fc80-4150-f1d9-f4c17e6944fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  Diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "842302    M      17.99        10.38        122.80          1001.0    0.11840   \n",
      "842517    M      20.57        17.77        132.90          1326.0    0.08474   \n",
      "84300903  M      19.69        21.25        130.00          1203.0    0.10960   \n",
      "84348301  M      11.42        20.38         77.58           386.1    0.14250   \n",
      "84358402  M      20.29        14.34        135.10          1297.0    0.10030   \n",
      "\n",
      "          smoothness_mean  compactness_mean  concavity_mean  concave_mean  \\\n",
      "842302            0.27760            0.3001         0.14710        0.2419   \n",
      "842517            0.07864            0.0869         0.07017        0.1812   \n",
      "84300903          0.15990            0.1974         0.12790        0.2069   \n",
      "84348301          0.28390            0.2414         0.10520        0.2597   \n",
      "84358402          0.13280            0.1980         0.10430        0.1809   \n",
      "\n",
      "          ...  fractal_seradius_worst  texture_worst  perimeter_worst  \\\n",
      "842302    ...                   25.38          17.33           184.60   \n",
      "842517    ...                   24.99          23.41           158.80   \n",
      "84300903  ...                   23.57          25.53           152.50   \n",
      "84348301  ...                   14.91          26.50            98.87   \n",
      "84358402  ...                   22.54          16.67           152.20   \n",
      "\n",
      "          area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "842302        2019.0            0.1622             0.6656           0.7119   \n",
      "842517        1956.0            0.1238             0.1866           0.2416   \n",
      "84300903      1709.0            0.1444             0.4245           0.4504   \n",
      "84348301       567.7            0.2098             0.8663           0.6869   \n",
      "84358402      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "          concave_worst  symmetry_worst  fractal_worst  \n",
      "842302           0.2654          0.4601        0.11890  \n",
      "842517           0.1860          0.2750        0.08902  \n",
      "84300903         0.2430          0.3613        0.08758  \n",
      "84348301         0.2575          0.6638        0.17300  \n",
      "84358402         0.1625          0.2364        0.07678  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#\n",
    "# base de dados disponível na UCI Machine Learning - https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic\n",
    "cancer_colunas = ['id','Diagnosis',\n",
    "                  'radius_mean','texture_mean','perimeter_mean', 'area_mean',\n",
    "                  'smoothness_mean','compactness_mean','concavity_mean',\n",
    "                  'concave_mean','symmetry_mean','fractal_mean',\n",
    "\n",
    "                  'radius_se','texture_se','perimeter_se', 'area_se','smoothness_se',\n",
    "                  'compactness_se','concavity_se','concave_se','symmetry_se','fractal_se'\n",
    "\n",
    "                  'radius_worst','texture_worst','perimeter_worst', 'area_worst',\n",
    "                  'smoothness_worst','compactness_worst','concavity_worst',\n",
    "                  'concave_worst','symmetry_worst','fractal_worst']\n",
    "cancer = pd.read_csv('data/wdbc.data',header=None,\n",
    "                     names=cancer_colunas, lineterminator='\\n', na_values='?')\n",
    "\n",
    "# visualizar parte dos dados\n",
    "print( cancer.head() )\n",
    "\n",
    "#\n",
    "# caso queira usar do google-drivre\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#drive.mount(“/content/drive”, force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRWfU5xhnjeS"
   },
   "source": [
    "Para baixar direto da web e tratar arquivos compactados, sem o uso de arquivos locais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4l-TY3ghluvM",
    "outputId": "09ada392-2f4f-4f07-ab7e-c4a5fb98de7d"
   },
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "r = requests.get('https://archive.ics.uci.edu/static/public/17/breast+cancer+wisconsin+diagnostic.zip')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.namelist()\n",
    "dadosfp = z.open('wdbc.data')\n",
    "dados = dadosfp.read()\n",
    "cancer2 = pd.read_csv(io.BytesIO(dados),header=None,\n",
    "                     names=cancer_colunas, lineterminator='\\n', na_values='?')\n",
    "print( cancer.head() )\n",
    "\n",
    "cancer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfN629xbuX-_"
   },
   "source": [
    "<h2>Hora de realizar os tratamentos<h2>\n",
    "<p>no exemplo, iremos normalizar as colunas, remover a coluna de identificação e separar a classe dos atributos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLrGqcAMulAE",
    "outputId": "0512a5ec-e5a5-4ee5-8d10-ca787cb395c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "842302          10.38        122.80          1001.0    0.11840   \n",
      "842517          17.77        132.90          1326.0    0.08474   \n",
      "84300903        21.25        130.00          1203.0    0.10960   \n",
      "84348301        20.38         77.58           386.1    0.14250   \n",
      "84358402        14.34        135.10          1297.0    0.10030   \n",
      "\n",
      "          smoothness_mean  compactness_mean  concavity_mean  concave_mean  \\\n",
      "842302            0.27760            0.3001         0.14710        0.2419   \n",
      "842517            0.07864            0.0869         0.07017        0.1812   \n",
      "84300903          0.15990            0.1974         0.12790        0.2069   \n",
      "84348301          0.28390            0.2414         0.10520        0.2597   \n",
      "84358402          0.13280            0.1980         0.10430        0.1809   \n",
      "\n",
      "          symmetry_mean  fractal_mean  ...  fractal_seradius_worst  \\\n",
      "842302          0.07871        1.0950  ...                   25.38   \n",
      "842517          0.05667        0.5435  ...                   24.99   \n",
      "84300903        0.05999        0.7456  ...                   23.57   \n",
      "84348301        0.09744        0.4956  ...                   14.91   \n",
      "84358402        0.05883        0.7572  ...                   22.54   \n",
      "\n",
      "          texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "842302            17.33           184.60      2019.0            0.1622   \n",
      "842517            23.41           158.80      1956.0            0.1238   \n",
      "84300903          25.53           152.50      1709.0            0.1444   \n",
      "84348301          26.50            98.87       567.7            0.2098   \n",
      "84358402          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "          compactness_worst  concavity_worst  concave_worst  symmetry_worst  \\\n",
      "842302               0.6656           0.7119         0.2654          0.4601   \n",
      "842517               0.1866           0.2416         0.1860          0.2750   \n",
      "84300903             0.4245           0.4504         0.2430          0.3613   \n",
      "84348301             0.8663           0.6869         0.2575          0.6638   \n",
      "84358402             0.2050           0.4000         0.1625          0.2364   \n",
      "\n",
      "          fractal_worst  \n",
      "842302          0.11890  \n",
      "842517          0.08902  \n",
      "84300903        0.08758  \n",
      "84348301        0.17300  \n",
      "84358402        0.07678  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "['M' 'B']\n"
     ]
    }
   ],
   "source": [
    "X = cancer.iloc[:,2:]\n",
    "cols = cancer_colunas[2:]\n",
    "print(X.head())\n",
    "Y = cancer['id']\n",
    "Y_orig = cancer['id']\n",
    "print(Y.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9uS7b_5CxTR"
   },
   "source": [
    "Na próxima seção que deverão ser realizada as tentativas de tratamento de dados, visando a melhoria no desempenho do classificador (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Tp4WMMPyuO2",
    "outputId": "bdcf62ed-c85e-4ac5-ca20-f1b92614ae33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "842302          10.38        122.80          1001.0    0.11840   \n",
      "842517          17.77        132.90          1326.0    0.08474   \n",
      "84300903        21.25        130.00          1203.0    0.10960   \n",
      "84348301        20.38         77.58           386.1    0.14250   \n",
      "84358402        14.34        135.10          1297.0    0.10030   \n",
      "\n",
      "          smoothness_mean  compactness_mean  concavity_mean  concave_mean  \\\n",
      "842302            0.27760            0.3001         0.14710        0.2419   \n",
      "842517            0.07864            0.0869         0.07017        0.1812   \n",
      "84300903          0.15990            0.1974         0.12790        0.2069   \n",
      "84348301          0.28390            0.2414         0.10520        0.2597   \n",
      "84358402          0.13280            0.1980         0.10430        0.1809   \n",
      "\n",
      "          symmetry_mean  fractal_mean  ...  fractal_seradius_worst  \\\n",
      "842302          0.07871        1.0950  ...                   25.38   \n",
      "842517          0.05667        0.5435  ...                   24.99   \n",
      "84300903        0.05999        0.7456  ...                   23.57   \n",
      "84348301        0.09744        0.4956  ...                   14.91   \n",
      "84358402        0.05883        0.7572  ...                   22.54   \n",
      "\n",
      "          texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "842302            17.33           184.60      2019.0            0.1622   \n",
      "842517            23.41           158.80      1956.0            0.1238   \n",
      "84300903          25.53           152.50      1709.0            0.1444   \n",
      "84348301          26.50            98.87       567.7            0.2098   \n",
      "84358402          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "          compactness_worst  concavity_worst  concave_worst  symmetry_worst  \\\n",
      "842302               0.6656           0.7119         0.2654          0.4601   \n",
      "842517               0.1866           0.2416         0.1860          0.2750   \n",
      "84300903             0.4245           0.4504         0.2430          0.3613   \n",
      "84348301             0.8663           0.6869         0.2575          0.6638   \n",
      "84358402             0.2050           0.4000         0.1625          0.2364   \n",
      "\n",
      "          fractal_worst  \n",
      "842302          0.11890  \n",
      "842517          0.08902  \n",
      "84300903        0.08758  \n",
      "84348301        0.17300  \n",
      "84358402        0.07678  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "['M' 'B']\n",
      "          radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "842302          10.38        122.80          1001.0    0.11840   \n",
      "842517          17.77        132.90          1326.0    0.08474   \n",
      "84300903        21.25        130.00          1203.0    0.10960   \n",
      "84348301        20.38         77.58           386.1    0.14250   \n",
      "84358402        14.34        135.10          1297.0    0.10030   \n",
      "\n",
      "          smoothness_mean  compactness_mean  concavity_mean  concave_mean  \\\n",
      "842302            0.27760            0.3001         0.14710        0.2419   \n",
      "842517            0.07864            0.0869         0.07017        0.1812   \n",
      "84300903          0.15990            0.1974         0.12790        0.2069   \n",
      "84348301          0.28390            0.2414         0.10520        0.2597   \n",
      "84358402          0.13280            0.1980         0.10430        0.1809   \n",
      "\n",
      "          symmetry_mean  fractal_mean  ...  fractal_seradius_worst  \\\n",
      "842302          0.07871        1.0950  ...                   25.38   \n",
      "842517          0.05667        0.5435  ...                   24.99   \n",
      "84300903        0.05999        0.7456  ...                   23.57   \n",
      "84348301        0.09744        0.4956  ...                   14.91   \n",
      "84358402        0.05883        0.7572  ...                   22.54   \n",
      "\n",
      "          texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "842302            17.33           184.60      2019.0            0.1622   \n",
      "842517            23.41           158.80      1956.0            0.1238   \n",
      "84300903          25.53           152.50      1709.0            0.1444   \n",
      "84348301          26.50            98.87       567.7            0.2098   \n",
      "84358402          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "          compactness_worst  concavity_worst  concave_worst  symmetry_worst  \\\n",
      "842302               0.6656           0.7119         0.2654          0.4601   \n",
      "842517               0.1866           0.2416         0.1860          0.2750   \n",
      "84300903             0.4245           0.4504         0.2430          0.3613   \n",
      "84348301             0.8663           0.6869         0.2575          0.6638   \n",
      "84358402             0.2050           0.4000         0.1625          0.2364   \n",
      "\n",
      "          fractal_worst  \n",
      "842302          0.11890  \n",
      "842517          0.08902  \n",
      "84300903        0.08758  \n",
      "84348301        0.17300  \n",
      "84358402        0.07678  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.022658  0.545989  0.363733  0.593753  0.792037  0.703140  0.731113   \n",
      "1  0.272574  0.615783  0.501591  0.289880  0.181768  0.203608  0.348757   \n",
      "2  0.390260  0.595743  0.449417  0.514309  0.431017  0.462512  0.635686   \n",
      "3  0.360839  0.233501  0.102906  0.811321  0.811361  0.565604  0.522863   \n",
      "4  0.156578  0.630986  0.489290  0.430351  0.347893  0.463918  0.518390   \n",
      "\n",
      "         7         8         9   ...        19        20        21        22  \\\n",
      "0  0.686364  0.605518  0.356147  ...  0.620776  0.141525  0.668310  0.450698   \n",
      "1  0.379798  0.141323  0.156437  ...  0.606901  0.303571  0.539818  0.435214   \n",
      "2  0.509596  0.211247  0.229622  ...  0.556386  0.360075  0.508442  0.374508   \n",
      "3  0.776263  1.000000  0.139091  ...  0.248310  0.385928  0.241347  0.094008   \n",
      "4  0.378283  0.186816  0.233822  ...  0.519744  0.123934  0.506948  0.341575   \n",
      "\n",
      "         23        24        25        26        27        28  \n",
      "0  0.601136  0.619292  0.568610  0.912027  0.598462  0.418864  \n",
      "1  0.347553  0.154563  0.192971  0.639175  0.233590  0.222878  \n",
      "2  0.483590  0.385375  0.359744  0.835052  0.403706  0.213433  \n",
      "3  0.915472  0.814012  0.548642  0.884880  1.000000  0.773711  \n",
      "4  0.437364  0.172415  0.319489  0.558419  0.157500  0.142595  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import pandas as pd\n",
    "\n",
    "X_orig =  X.copy()\n",
    "print(X_orig.head())\n",
    "\n",
    "print(Y_orig.unique() )\n",
    "\n",
    "# normalização min-max\n",
    "X = pd.DataFrame( minmax_scale(X) )\n",
    "\n",
    "print(X_orig.head())\n",
    "print(X.head())\n",
    "\n",
    "# A normalização pode ser manual, usando o pandas... ex:\n",
    "#X['radius_mean'] = (X_orig['radius_mean']-X_orig['radius_mean'].mean()) / X_orig['radius_mean'].std()\n",
    "# normalização min-max\n",
    "#X['texture_mean'] = (X_orig['texture_mean']-X_orig['texture_mean'].min()) / (X_orig['texture_mean'].max()-X_orig['texture_mean'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBZUGabt2eZv"
   },
   "source": [
    "A próxima seção trata da construção do modelo, dos testes e das métricas da matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hDFNHGyF20UV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# com os dados originais\n",
    "X_oring_train, X_orig_test, y_orig_train, y_orig_test = train_test_split(X_orig,\n",
    "                      Y_orig, test_size=0.25, stratify=Y_orig,random_state=10)\n",
    "\n",
    "# com os dados tratados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25,\n",
    "                                                    stratify=Y,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsF5IaEU49xG"
   },
   "source": [
    "Treina o modelo com base nos dados originais (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xyxTe-q49T_",
    "outputId": "3323ca47-fbc4-4eed-ccfe-0f3eeccf3a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão - com os dados ORIGINAIS usados no TREINAMENTO\n",
      "[[265   2]\n",
      " [ 34 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.89      0.99      0.94       267\n",
      "           M       0.98      0.79      0.87       159\n",
      "\n",
      "    accuracy                           0.92       426\n",
      "   macro avg       0.94      0.89      0.91       426\n",
      "weighted avg       0.92      0.92      0.91       426\n",
      "\n",
      "Matriz de confusão - com os dados ORIGINAIS usados para TESTES\n",
      "[[87  3]\n",
      " [ 9 44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.91      0.97      0.94        90\n",
      "           M       0.94      0.83      0.88        53\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.92      0.90      0.91       143\n",
      "weighted avg       0.92      0.92      0.91       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "treinador = svm.SVC()  #algoritmo escolhido\n",
    "\n",
    "modelo_orig = treinador.fit(X_oring_train, y_orig_train)\n",
    "\n",
    "# predição com os mesmos dados usados para treinar\n",
    "y_orig_pred = modelo_orig.predict(X_oring_train)\n",
    "cm_orig_train = confusion_matrix(y_orig_train, y_orig_pred)\n",
    "print('Matriz de confusão - com os dados ORIGINAIS usados no TREINAMENTO')\n",
    "print(cm_orig_train)\n",
    "print(classification_report(y_orig_train, y_orig_pred))\n",
    "\n",
    "# predição com os mesmos dados usados para testar\n",
    "print('Matriz de confusão - com os dados ORIGINAIS usados para TESTES')\n",
    "y2_orig_pred = modelo_orig.predict(X_orig_test)\n",
    "cm_orig_test = confusion_matrix(y_orig_test, y2_orig_pred)\n",
    "print(cm_orig_test)\n",
    "print(classification_report(y_orig_test, y2_orig_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PdacgFz9mX3"
   },
   "source": [
    "Como os dados ficam após os processos de tratamento dos dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOeKrnRB9rU_",
    "outputId": "2518d42b-23f3-43c4-b490-33a0c72a7eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusão - com os dados TRATADOS usados no TREINAMENTO\n",
      "[[267   0]\n",
      " [  8 151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      1.00      0.99       267\n",
      "           M       1.00      0.95      0.97       159\n",
      "\n",
      "    accuracy                           0.98       426\n",
      "   macro avg       0.99      0.97      0.98       426\n",
      "weighted avg       0.98      0.98      0.98       426\n",
      "\n",
      "Matriz de confusão - com os dados ORIGINAIS usados para TESTES\n",
      "[[89  1]\n",
      " [ 1 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.99      0.99      0.99        90\n",
      "           M       0.98      0.98      0.98        53\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "treinador = svm.SVC()  #algoritmo escolhido\n",
    "\n",
    "modelo = treinador.fit(X_train, y_train)\n",
    "\n",
    "# predição com os mesmos dados usados para treinar\n",
    "y_pred = modelo.predict(X_train)\n",
    "cm_train = confusion_matrix(y_train, y_pred)\n",
    "print('Matriz de confusão - com os dados TRATADOS usados no TREINAMENTO')\n",
    "print(cm_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "# predição com os mesmos dados usados para testar\n",
    "print('Matriz de confusão - com os dados ORIGINAIS usados para TESTES')\n",
    "y2_pred = modelo.predict(X_test)\n",
    "cm_test = confusion_matrix(y_test, y2_pred)\n",
    "print(cm_test)\n",
    "print(classification_report(y_test, y2_pred))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
